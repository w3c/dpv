{% from 'macro_term_table.jinja2' import table_classes %}
{% from 'macro_term_table.jinja2' import table_properties %}
{% from 'macro_term_table.jinja2' import list_hierarchy, index_concepts, anchor %}
{% from 'macro_dpv_document_family.jinja2' import dpv_document_family, sotd, funding_acknowledgements, contributors_list, authors_list %}
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>{% block title %}{{data[vocab_name+'-metadata']['dct:title']}}{% endblock title %}</title>
  <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove" defer></script>
  {% block RESPEC %}
  <script class="remove">
   // All config options at https://respec.org/docs/ 
   var respecConfig = {
    shortName: "eu-aiact",
    title: "{{data[vocab_name+'-metadata']['dct:title']}} ({{vocab_name|upper}})",
    subtitle: "version {{data[vocab_name+'-metadata']['schema:version']}}",
    publishDate: "{{data[vocab_name+'-metadata']['dct:modified']}}",
    specStatus: "{{vocab_name|get_document_status}}",
    group: "dpvcg",
    latestVersion: "https://w3id.org/dpv/legal/eu/aiact",
    canonicalUri: "https://w3id.org/dpv/legal/eu/aiact",
    edDraftURI: "https://dev.dpvcg.org/legal/eu/aiact",
    github: "w3c/dpv",
    subjectPrefix: "[eu-aiact]",
    doJsonLd: true,
    lint: { "no-unused-dfns": false, "local-refs-exist": true },
    editors: [
    {
        "name": "Delaram Golpayegani",
        "company": "{{ "Delaram Golpayegani" | generate_author_affiliation }}"
    },
    {
      name: "Harshvardhan J. Pandit",
      url: "https://harshp.com",
      "company": "{{ "Harshvardhan J. Pandit" | generate_author_affiliation }}"
    }
    ],
    authors: {{ authors_list(data, vocab_name) }},
    otherLinks: [
      {
        "key": "This Release",
        "data": [
            {
              "value": "https://w3id.org/dpv/{{DPV_VERSION}}/legal/eu/aiact",
              "href": "https://w3id.org/dpv/{{DPV_VERSION}}/legal/eu/aiact"
            }
        ]
      },
      {
        "key": "Previous Release",
        "data": [
            {
              "value": "https://w3id.org/dpv/{{DPV_PREVIOUS_VERSION}}/legal/eu/aiact",
              "href": "https://w3id.org/dpv/{{DPV_PREVIOUS_VERSION}}/legal/eu/aiact"
            }
        ]
      },
      {
        "key": "Changelog",
        "data": [
            {
              "value": "Changelog for v{{DPV_VERSION}}",
              "href": "#changelog"
            }
        ]
      },
      {
        "key": "Key Publications",
        "data": [
            {
              "value": "Data Privacy Vocabulary (DPV) -- Version 2.0 (2024)",
              "href": "https://doi.org/10.1007/978-3-031-77847-6_10"
            },
            {
              "value": "To Be High-Risk, or Not To Be—Semantic Specifications and Implications of the AI Act’s High-Risk AI Applications and Harmonised Standards (2023)",
              "href": "https://doi.org/10.1145/3593013.3594050"
            },
            {
              "value": "AIRO: an Ontology for Representing AI Risks based on the Proposed EU AI Act and ISO Risk Management Standards (2022)",
              "href": "https://doi.org/10.3233/SSW220008"
            }
        ]
      }
    ],
    localBiblio: {%  include 'references.json' %}
  };
</script>
{% endblock RESPEC %}
<link rel="stylesheet" type="text/css" href="../../diagrams/common.css">
<link rel="shortcut icon" href="../../../diagrams/favicon-16x16.png" type="image/x-icon" sizes="16x16" />
  <link rel="shortcut icon" href="../../../diagrams/favicon-32x32.png" type="image/x-icon" sizes="32x32" />
</head>
<body>
  {{ contributors_list(data, vocab_name) }}
{% block ABSTRACT %}
  <section id="abstract">
    <p>The EU-AIAct extension extends the [[[DPV]]] to provide concepts such as systems, purposes, risks, roles, documentation, and assessments based on the [[[AIAct]]]. The canonical URL for EU-AIAct extension is <a href="https://w3id.org/dpv/legal/eu/aiact">https://w3id.org/dpv/legal/eu/aiact</a>, the namespace for terms is <a href="https://w3id.org/dpv/legal/eu/aiact#"><code>https://w3id.org/dpv/legal/eu/aiact#</code></a>, the suggested prefix is <code>eu-aiact</code>, and this document along with source and releases are available at <a href="https://github.com/w3c/dpv">https://github.com/w3c/dpv</a>.</p>
  </section>
    {{ sotd(DPV_VERSION=DPV_VERSION, metadata=data[vocab_name+'-metadata']) }}
    {{ dpv_document_family(document='eu-aiact-spec') }}
{% endblock ABSTRACT %}
{% block INTRODUCTION %}
  <section id="motivation">
    <h2>Introduction</h2>
    <p>The [[[AIAct]]] is a landmark regulation which regulates the use of Artificial Intelligence (AI) technologies. To support its implementation, the [[EU-AIAct]] extension provides relevant concepts which can be used to describe the facts of how AI is being developed and used within use-cases, and to produce the required documentation necessary for establishing or verifying compliance with the [[AIAct]]. Concepts in this extension extend relevant concepts defined in [[[DPV]]], as well as those defined in [[[AI]]] and [[[TECH]]] extensions.</p>
    <p>At the moment, the [[EU-AIAct]] extension provides the following concepts and taxonomies as defined or interpreted from the [[AIAct]]:</p>
    <ul>
      <li><a href="#vocab-system">AI systems</a>, such as general purpose AI systems or those using biometrics</li>
      <li><a href="#vocab-capability">Capabilities</a>, such as to produce deep fakes or perform biometric identification</li>
      <li><a href="#vocab-risk">Risk categorisations</a>, such as defining serious incidents or systemic risks at EU level</li>
      <li><a href="#vocab-data">Data categorisations</a>, such as training and testing data</li>
      <li><a href="#vocab-roles">Legal roles</a>, such as the AI Deployers and Providers</li>
      <li><a href="#vocab-docs">Documentation</a>, such as technical documentation </li>
      <li><a href="#vocab-status">Statuses</a>, such as market availability and supply of services</li>
      <li><a href="#vocab-assessment">Assessments</a>, such as conformity assessment and fundamental rights impact assessment</li>
      <li><a href="#vocab-misc">other concepts</a>, such as substantial modification and reasonably foreseeable misuses</li>
    </ul>
  </section>
{% endblock INTRODUCTION %}
{% block VOCAB %}

<section id="vocab">
  <h2>Concepts for AI Act</h2>

  <section id="vocab-system">
    <h3>AI System</h3>
    <p>The concept [=AISystem=] represents AI systems as defined in the AI Act.</p>
    
    {{ list_hierarchy(modules['system']['classes']) }}
  </section>

  <section id="vocab-capability">
    <h3>Purposes &amp; Capabilities</h3>
    <p>These concepts represent the purposes and capabilities defined within the AI Act. The use of 'capability' here refers to the capability of the technology to produce, perform, or achieve something, which is expressed in the [[TECH]] extension as <code>tech:Capability</code> and extended in the [[AI]] extension as <code>ai:Capability</code>.</p>
    
    {{ list_hierarchy(modules['capability']['classes']) }}
  </section>

  <section id="vocab-risk">
    <h3>Risk</h3>
    <p>The AI Act has a specific definition of risk as "combination of the probability of an occurrence of harm and the severity of that harm", which is represented using the concept [=Risk=] within this extension. This definition is a more specific form of {{anchor('dpv:Risk')}}, and hence the existing relations can be used to describe its severity and likelihood.</p>
    {{ list_hierarchy(modules['risk']['classes']) }}
  </section>

  <section id="vocab-risk-levels">
    <h2>Risk Levels</h2>
    <p>The interpretation of the AI Act uses terminology referring to <i>Risk Levels</i> which determine the level of obligations under the Act. To represent these, the concept [=RiskLevel=] is defined and instantiated to represent the commonly used concepts for representing prohibited, high-risk, transparency required, and minimal risk levels. The taxonomy also contains two additional concepts to represent not-prohibited and not-high-risk to support documenting outcomes of assessments that test prohibited and high-risk categorisations respectively.</p>
    {{ list_hierarchy(modules['risk-levels']['classes'], head='eu-aiact:RiskLevel') }}
    <aside class="example" title="Representing the Risk Level as per AI Act">
      <p>The example shows how the risk level for the AI Act can be associated with a process or with a specific AI system.</p>
<pre><code># method 1: Process/Services
ex:SomeService a dpv:Process ;
  dpv:hasPurpose ex:SomePurpose ; # from DPV purpose taxonomy
  ai:hasTechnique ex:SomeTechnique ; # from AI technique taxonomy
  dpv:hasRiskLevel eu-aiact:RiskLevelHighAnnexIII .

ex:SomeSystem a eu-aiact:AISystem ;
  dpv:hasRiskLevel eu-aiact:RiskLevelHighAnnexIII .
ex:SomeProcess a dpv:Process ;
  ai:hasAISystem ex:SomeSystem . # uses high-risk AI
</code></pre>
    </aside>
    <aside class="note" title="Scope vs Risk Level">
      <p>The concept of "Risk Level" should not be mixed with the "scope" of the AI Act. The concept of [=RiskLevelMinimal=] is used to represent AI systems or practices that fit the definition of AI and AI systems under the Act but are not prohibited, high-risk, or require transparency. This is distinct from AI systems and practices which do not fit the (rigid and specific) definitions of AI and AI systems under the AI Act. This reflects the procedure where you first determine whether a system is an AI system as defined by the AI Act (scope determination) and then how it is categorised under the AI Act (risk level determination).</p>
    </aside>
  </section>

  <section id="vocab-data">
    <h3>Data</h3>
    <p>The AI Act defines different categories of data as used to develop and deploy AI systems, such as [=TrainingData=] and [=TestingData=]. It also uses [=Biometric=] which is a special category of personal data under [[GDPR]].</p>
    
    {{ list_hierarchy(modules['data']['classes']) }}
  </section>

  <section id="vocab-roles">
    <h3>Entity Roles</h3>
    <p>AI Roles describe the categorisation of entities based on the role they take in developing, providing, deploying, or using an AI system as defined within the [[AIAct]].</p> 
    
    {{ list_hierarchy(modules['roles']['classes']) }}
  </section>

  <section id="vocab-docs">
    <h3>Documentation</h3>
    <p>The documentation associated with AI, AI systems, and other processes defined within the AI Act. These are described using <code>tech:Documentation</code> from the [[TECH]] extension.</p>
    
    {{ list_hierarchy(modules['docs']['classes']) }}
  </section>

  <section id="vocab-status">
    <h3>Statuses</h3>
    <p>Different statuses are described or implied within the [[AIAct]], such as [=MarketAvailabilityStatus=] regarding whether the AI system is available on the market, and [=ServiceSupplyStatus=] regarding whether the AI system has been supplied. These statuses reflect the requirement to describe the state of the AI system and its use, which has implications in terms of requirements and obligations.</p>
    
    {{ list_hierarchy(modules['status']['classes']) }}
  </section>

  <section id="vocab-assessment">
    <h3>Assessments</h3>
    <p>Compliance with requirements of the [[AIAct]], e.g affixing [=CEMarking=] or implementing a [=PostMarketMonitoringSystem=], requires various types of assessments. These are described using [[DPV]] concepts such as <code>dpv:CertificationSeal</code> and <code>dpv:ImpactAssessment</code>.</p>
    
    {{ list_hierarchy(modules['assessment']['classes']) }}
  </section>

  <section id="vocab-compliance">
    <h3>Compliance</h3>
    <p>The concepts in this section reflect the status of processing operations being in <i>compliance with AI Act</i>, by extending the <code>ComplianceStatus</code> from DPV for AI Act. It does not define the requirements for compliance itself. To indicate these, the relation <code>dpv:hasLawfulness</code> can be used.</p>
    <aside class="example" title="Indicating status of AI Act lawfulness">
      <p>This example shows the use of EU-AIAct to indicate the state of AIAct lawfulness associated with two processes. The first is asserted to be compliant, while the compliance status for the second is unknown at the moment. Both processes assert the applicability of AI Act for brevity.</p>
      <pre class="nohighlight"><code>ex:PDH1 a dpv:Process ;
  dpv:hasApplicableLaw legal-eu:AIAct ;
  dpv:hasLawfulness eu-aiact:AIActCompliant .

ex:PDH3 a dpv:Process ;
  dpv:hasApplicableLaw legal-eu:AIAct ;
  dpv:hasLawfulness eu-aiact:AIActComplianceUnknown .
      </code></pre>
    </aside>
    {{ list_hierarchy(modules['compliance']['classes']) }}
  </section>

  <section id="vocab-sector">
    <h3>Sectors</h3>
    <p>The [[AIAct]] implicitly refers to various sectors, such as when stating the high-risk uses of AI systems in Annex III. To enable referring to such implied sectors, this extension provides an ad-hoc taxonomy. This taxonomy may change in the future as sectors are also an important concept in other laws, such as [[EU-NIS2]]</p>
    
    {{ list_hierarchy(modules['sector']['classes']) }}
  </section>

  <section id="vocab-misc">
    <h3>Misc. Concepts</h3>
    <p>These concepts currently do not fit within the other stated categories, and are pooled together under a 'misc.' label while the vocabulary is being further developed.</p>
    
    {{ list_hierarchy(modules['misc']['classes']) }}
  </section>
</section>

<section id="high-risk-prohibited">
  <h2>High-Risk &amp; Prohibited AI Systems</h2>
  <p>The AI Act defines specific uses of AI systems as being 'prohibited' (Article 5) or as being 'high-risk' (Article 6). To support the expression of these high-risk AI systems using DPV concepts and the risk levels described earlier, the following concepts are being discussed for inclusion in future versions of this vocabulary:</p>
  <ol>
    <li><code>ProhibitedAISystem</code> as a subtype of [=AISystem=] to represent each specific AI system that has been prohibited as per Article 5.</li>
    <li><code>HighRiskAISystem</code> as a subtype of [=AISystem=] to represent each specific AI system that has been designated as high-risk as per Article 6.
      <ol>
        <li><code>SectorialHighRiskAISystem</code> as a subtype of <code>HighRiskAISystem</code> to represent AI systems that have been prohibited as per Article 6 and Annex I (sector-specific regulated uses of AI).</li>
        <li><code>HighRiskApplicationAISystem</code> as a subtype of <code>HighRiskAISystem</code> to represent AI systems that have been prohibited as per Article 6 and Annex III (specific applications).</li>
      </ol>
    </li>
    <li><code>NonHighRiskAISystem</code> as a subtype of [=AISystem=] to represent AI systems that have not been prohibited as per Article 5, and are not designated as high-risk as per Article 6.</li>
  </ol>

  <section id="high-risk">
    <h3>High-Risk AI Systems</h3>    
    <aside class="note" title="Work in progress">
      <p>This section reflects the work in progress for expressing specific applications described in Annex III using DPV concepts, based on the work "<a href="https://doi.org/10.1145/3593013.3594050">To Be High-Risk, or Not To Be—Semantic Specifications and Implications of the AI Act’s High-Risk AI Applications and Harmonised Standards (Golpayegani et. al - FAccT 2023)</a>". We welcome help/support for this.</p>
    </aside>
    <p>The below is a list mapping the clauses in Annex III to specific purposes in DPV vocabularies.</p>
    <ul>
      <li><strong>Anx.III-1a</strong> -  IdentityVerification</li>
      <li><strong>Anx.III-1b</strong> -  n/a</li>
      <li><strong>Anx.III-1c</strong> -  n/a</li>
      <li><strong>Anx.III-2</strong> -   CriticalInfrastructureManagement, CriticalEnergyManagement, CriticalElectricityManagement, CriticalGasManagement, CriticalWaterManagement, CriticalHeatingManagement, CriticalDigitalInfrastructureManagement</li>
      <li><strong>Anx.III-3a</strong> -  EducationAccessManagement, EducationStudentAdmissionManagement, EducationStudentAllocation</li>
      <li><strong>Anx.III-3b</strong> -  EducationStudentLearningOutcomeAssessment</li>
      <li><strong>Anx.III-3c</strong> -  EducationStudentAcademicPotentialAssessment, EducationStudentLearningNeedsAssessment</li>
      <li><strong>Anx.III-3d</strong> -  EducationStudentProctoring</li>
      <li><strong>Anx.III-4a</strong> -  JobApplicantRecruitment, JobApplicantSelection, TargetedJobAdvertising, JobApplicationAnalysis, JobApplicationScreening, JobInterviewAssessment</li>
      <li><strong>Anx.III-4b</strong> -  PersonnelPromotionManagement, PersonnelTerminationManagement, PersonnelBehaviourMonitoring, PersonnelWorkloadManagement, PersonnelPerformanceMonitoring</li>
      <li><strong>Anx.III-5a</strong> -  PublicServiceEligibilityAssessment, SocialWelfareEligibilityAssessment, HealthcareEligibilityAssessment, PublicServiceDistributionManagement, SocialWelfareDistributionManagement</li>
      <li><strong>Anx.III-5b</strong> -  CreditChecking, MaintainCreditCheckingDatabase, FinancialFraudManagement</li>
      <li><strong>Anx.III-5c</strong> -  InsuranceRiskAssessment, InsurancePricingManagement, HealthInsuranceManagement, LifeInsuranceManagement </li>
      <li><strong>Anx.III-5d</strong> -  EmergencyResponseEligibilityAssessment, EmergencyResponseCommunicationManagement, EmergencyResponseTriage, EmergencyResponseDispatchManagement, HealthcareEmergencyCareTriage</li>
      <li><strong>Anx.III-6a</strong> -  CrimeVictimPrediction</li>
      <li><strong>Anx.III-6b</strong> -  LegalInterrogation</li>
      <li><strong>Anx.III-6c</strong> -  LegalEvidenceEligibilityAssessment, CrimeInvestigation, LegalOffenceProsecution</li>
      <li><strong>Anx.III-6d</strong> -  LegalOffencePrediction, LegalRepeatOffencePrediction</li>
      <li><strong>Anx.III-6e</strong> -  CrimeDetection, CrimeInvestigation, CrimeProsecution</li>
      <li><strong>Anx.III-7a</strong> -  LegalInterrogation</li>
      <li><strong>Anx.III-7b</strong> -  ImmigrationSecurityManagement, ImmigrationHealthRiskManagement, UnauthorisedMigrationManagement</li>
      <li><strong>Anx.III-7c</strong> -  ImmigrationEligibilityAssessment, ImmigrationApplicationManagement, ImmigrationRequestManagement, ImmigrationVisaManagement, ImmigrationResidencyPermitManagement, ImmigrationAsylumManagement, ImmigrationComplaintManagement</li>
      <li><strong>Anx.III-7d</strong> -  ImmigrationAsylumManagement, ImmigrationMigrationManagement, ImmigrationBorderControlManagement, ImmigrationIdentityVerification, ImmigrationDocumentVerification</li>
      <li><strong>Anx.III-8a</strong> -  JudicialLegalInterpretation, JudicialDisputeManagement</li>
      <li><strong>Anx.III-8b</strong> -  PoliticalCampaign</li>
    </ul>
  </section>

  <section id="prohibited">
    <h3>Prohibited AI Systems</h3>
    <aside class="note" title="Work in progress">
      <p>This section reflects the work in progress for expressing specific prohibitions described in Article 5 using DPV concepts. We welcome help/support for this.</p>
    </aside>
  </section>

</section>

<section id="FRIA">
  <h2>FRIA</h2>
   <aside class="note" title="Work in progress">
      <p>This section reflects the work in progress for providing concepts and support the Fundamental Rights Impact Assessments (FRIA) as described in Article 27 using DPV concepts. See the articles <a href="https://harshp.com/research/publications/074-FRIA-Tool-DPIA">Towards An Automated AI Act FRIA Tool That Can Reuse GDPR's DPIA</a> and <a href="https://harshp.com/research/publications/075-FRIA-Ontology"> Developing an Ontology for AI Act Fundamental Rights Impact Assessments</a> for more details on ongoing work. We welcome help/support for this.</p>
    </aside>
</section>

<section id="vocabulary">
<h2>Vocabulary Index</h2>
  <section id="dpv-classes">
    {{ index_concepts(vocab, vocab_name, filter="classes") }}
  </section>
  <section id="dpv-properties">
    {{ index_concepts(vocab, vocab_name, filter="properties") }}
  </section>
  <section id="external-concepts">
    <p>DPV uses the following terms from [[RDF]] and  [[RDFS]] with their defined meanings:</p>
    <ul>
      <li id="rdf:type"><dfn>rdf:type</dfn> to denote a concept is an instance of another concept</li>
      <li id="rdfs:Class"><dfn>rdfs:Class</dfn> to denote a concept is a Class or a category</li>
      <li id="rdfs:subClassOf"><dfn>rdfs:subClassOf</dfn> to specify the concept is a subclass (subtype, sub-category, subset) of another concept</li>
      <li id="rdf:Property"><dfn>rdf:Property</dfn> to denote a concept is a property or a relation</li>
      </ul>
    <p>The following external concepts are re-used within DPV:</p>
    {{ index_concepts(vocab, vocab_name, filter="external") }}
  </section>
</section>
{% endblock VOCAB %}

<section id="future-work" class="appendix">
  <h2>Future Work</h2>
  <aside class="issue" data-number="199"></aside>
  <aside class="issue" data-number="229"></aside>
  <aside class="issue" data-number="230"></aside>
  <aside class="issue" data-number="231"></aside>
</section>

{% block ACKNOWLEDGEMENTS %}
<section id="funding-acknowledgements" class="notoc">
  <h2>Funding Acknowledgements</h2>

  <h3>Funding Sponsors</h3>
  {{ funding_acknowledgements() }}

  <h3>Funding Acknowledgements for Contributors</h3>
  <p>The contributions of Delaram Golpayegani have received funding through the <a href="https://protect-network.eu/">PROTECT ITN Project</a> from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No 813497, in particular through the development of <a href="https://w3id.org/airo">AI Risk Ontology (AIRO)</a> and <a href="https://w3id.org/vair">Vocabulary of AI Risks (VAIR)</a> which have been integrated in to this extension.</p>
  <p>The contributions of Harshvardhan J. Pandit have been made with the financial support of Science Foundation Ireland under Grant Agreement No. 13/RC/2106_P2 at the ADAPT SFI Research Centre.</p>

</section>
{% endblock ACKNOWLEDGEMENTS %}

{% block PROPOSED %}
{% if proposed %}
<section id="proposed-terms" class="appendix">
  <h2>Proposed Terms</h2>
  <p>The following terms have been proposed for inclusion, and are under discussion. They are provided here for illustrative purposes and should not be considered as part of DPV.</p>
  {% for name, terms in proposed.items() %}
    <strong>{{name}}</strong>
    <ul>{% for term in terms %}
      <li>{{term}}</li>
    {% endfor %}</ul>
  {% endfor %}
</section>
{% endif %}
{% endblock PROPOSED %}
<section class="appendix" id="issue-summary"></section>

<section id="changelog">
  <h2>Changelog for v{{DPV_VERSION}}</h2>
  <div class="issue" title="Changelog for v{{DPV_VERSION}}"></div>
</section>

<script type="text/javascript" src="../../diagrams/common.js" defer></script>
</body>
</html>
